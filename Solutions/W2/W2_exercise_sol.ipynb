{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Week 2: Background subtraction\n\nThis python notebook includes all the exercises from this session. All the needed setup, I/O and user-interaction code is already provided to let you concentrate on this week's topic.<br>\nPlease run all the provided code in order before running yours.<br>\n\nThis week's assignment:\n\n## 1. Bluescreen\n### 1.A Single pixel model\nExtract foreground objects in bluescreen movie footage. The blue background color should be specified by a single color value [r, g, b]. You may obtain such a value by using the provided notebook widget to select one or more blue pixels on the first frame of the footage. To determine whether a given pixel should be foreground or background, threshold the absolute distance of its value to the reference value, i.e.\n\n$$\\left\\lVert[r, g, b] âˆ’ [r_0, g_0, b_0]\\right\\rVert < t$$\n\nBased on pixelwise decisions, a mask can be created to specify foreground and background.<br>\nTry different values for the threshold and the reference color. To test your results, you can use the short video provided. Note that not the whole background consists of bluescreen.\nTo overcome this problem, you can use the precomputed mask provided into the variable `mask`.\n\n### 1.B Exemplar set model\nTo further improve the results, specify the blue background by an exemplar set of blue background pixels. You may select this set using the same widget as in the previous point. After computing mean $\\mu$ and covariance matrix $\\Sigma$ of the pixel values, the Mahalanobis distance $M(x, \\mu, \\Sigma)$ can be used to decide whether a color value $x$ originated from the background or the foreground.\n\n$$M(x, \\mu, \\Sigma) = \\sqrt{(x-\\mu)^T\\Sigma^{-1}(x-\\mu)}$$\n\n## 2. Per-pixel Model\nProbably you have noticed that the approach in the previous task failed in the upper region of the background, which was not covered with blue sheets, for which we provided the `mask`. To handle more complex scenarios, extend the background model to a per-pixel model. For each pixel, compute the mean and the covariance of its values over a number of frames which do not contain foreground objects. You may then use the Mahalanobis distance to classify pixels in sequences containing foreground objects. You can use the same threshold for all pixels.<br>\nTo create the model, use jugglingBG.avi. This scene was captured for several frames without foreground objects. Based on the background model, foreground pixels can then be identified and masks can be created for jugglingTest.avi."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Useful information for this tutorial:\n\nImages are represented as numpy arrays, which are fixed-dimensional arrays. Videos are represented as arrays of images.<br>\nIn this tutorial each pixel takes a RGB value within the range [0-255] and is represented as a 16-bit signed integer, to allow signed operations without subtle overflow bugs.\n\nyou will need to visualize your results, thus to printout an image use:\n\n`imshow(image)`\n\nYou can read pixel values inside an image by accessing the corresponding pixel coordinates in the array. The following reads the green component (1) of pixel at location (10, 20) of the 5th frame (index 4):\n\n`g = vid[4, 10, 20, 1]`\n\nOf course you can also change pixel values in the same way. We recommend copying an image before editing. To copy an image:\n\n`im_copy = np.array(im)` (`np` is the short name for `numpy` which is recognized by python when importing numpy with `import numpy as np`)\n\nWith numpy it is also possible to refer to slices of a given array by specifying the kept dimensions in the slice with `:`. For example, if we want to access the red channel of an RGB image `im` with shape `(height, width, 3)`, we can write `im[:, :, 0]`, which refers to the whole image data for the red channel only. We can optionally specify a range to be kept along a direction by writing the extreme indices around the `:` as in `min:max`. For example, accessing a patch within the pixel coordinates `(h0, w0)`, `(h1, w1)` with h0 < h1 and w0 < w1 can be done with `im[h0:h1, w0:w1, :]`.<br>\nYou can also index arrays based on conditions: for example to set to black all pixels with a blue component higher than 200 you can write `im[im[:, :, 2] > 200] = 0`.<br>\nThese references can be used both for reading an image slice and for writing a whole slice at once, without looping over it.\n\nWhen doing operations between numpy arrays, all operations are executed element-wise (except for the `@` operator that performs the usual matrix multiplication). This requires the shapes (dimensions) of the involved arrays to match or to be compatible according to broadcasting rules, which are usually intuitive. An example of broadcasting is when adding a pixel value `p=np.array([70, 128, 255])` to an image `im` with shape `(height, width, 3)`: the operation is legal and the pixel value is added independently to each pixel in the image. A complete reference of numpy broadcasting rules (not necessary for this tutorial, but very useful for numpy python programming) can be found in https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html . \n\nIn the following we list some useful functions:\n\n`np.array(a)`: returns a copy of `a` as a numpy array. Argument `a` does not need to be a numpy array, it can be any array-like object, e.g. a python list. https://docs.scipy.org/doc/numpy/reference/generated/numpy.array.html<br>\n`np.empty(shape, dtype)`: returns a new empty array with specified shape `shape` and the specified data type `dtype`. For this tutorial we suggest using as dtype `np.int16` for images and default for the rest. https://docs.scipy.org/doc/numpy/reference/generated/numpy.empty.html<br>\n`np.ones(shape, dtype)`: returns a new array filled with ones with specified shape `shape` and the specified data type `dtype`. For this tutorial we suggest using as dtype `np.int16` for images and default for the rest. https://docs.scipy.org/doc/numpy/reference/generated/numpy.ones.html<br>\n`np.zeros(shape, dtype)`: returns a new array filled with zeros with specified shape `shape` and the specified data type `dtype`. For this tutorial we suggest using as dtype `np.int16` for images and default for the rest. https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html<br>\n`np.eye(N)` : builds the identity matrix of order `N`. https://docs.scipy.org/doc/numpy/reference/generated/numpy.eye.html<br>\n`np.reshape(a, newshape)`: returns a reshaped view of the input array `a` having shape `newshape`, which should be specified as a tuple of integers. https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html<br>\n`np.linalg.norm(x)`: returns the L2 norm of array `x`. You can also specify a keyword argument `axis` to compute the norm only along a specific dimension (the result will have the same shape as `x`, but without the specified dimension) https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.norm.html<br>\n`np.transpose(a)` : returns the transposed of array `a`, whose shape has reversed order with respect to `a`. Alias `a.T`. https://docs.scipy.org/doc/numpy/reference/generated/numpy.transpose.html<br>\n`np.linalg.inv(a)` : returns the multiplicative inverse of matrix `a`. https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.inv.html<br>\n`np.matmul(a, b)` : returns the matrix multiplication of `a` multiplied by `b`. Alias `a @ b`. https://docs.scipy.org/doc/numpy/reference/generated/numpy.matmul.html<br>\n`np.sum(a)` : returns the sum of all the elements of array `a`. You can specify a keyword argument `axis` to compute the sum only along a specific dimension (the result will have the same shape as `a`, but without the specified dimension) https://docs.scipy.org/doc/numpy/reference/generated/numpy.sum.html<br>\n`np.mean(a)` : returns the mean value of all the elements of array `a`. You can specify a keyword argument `axis` to compute the mean only along a specific dimension (the result will have the same shape as `a`, but without the specified dimension) https://docs.scipy.org/doc/numpy/reference/generated/numpy.mean.html<br>\n`np.cov(m)` : build the covariance matrix of array `a` where each row represents a variable and each column represents an observation.  https://docs.scipy.org/doc/numpy/reference/generated/numpy.cov.html <br>\n\n"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## EXERCISE 1 - SETUP CODE"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The following cell installs required packages into the virtual machine that will run your code"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install scikit-video\n!pip install scikit-image",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Import packages to read videos, make interactive widgets and plot images."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import skvideo.io\nimport skimage.io\nimport matplotlib\nfrom ipywidgets import interactive, widgets\nfrom IPython.display import display\nfrom matplotlib.pyplot import imshow\nimport numpy as np\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Reading the test video bluescreen.avi in `bluescreen` and the upper region mask into `umask`."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "bluescreen = np.array(skvideo.io.vread(\"bluescreen.avi\"), dtype=np.int16)\nnumframes, height, width, channels = np.shape(bluescreen)\nprint(\"Video information:\")\nprint(\"Number of frames: \", numframes)\nprint(\"Frame width (pixels): \", width)\nprint(\"Frame height (pixels): \", height)\nprint(\"Video array shape: \", np.shape(bluescreen))\n\numask = skimage.io.imread(\"mask.bmp\")//255",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Here is a \\*wonderful\\* user interface we have prepared for you to select any number of points on the first frame of the video.\n\nUse the x slider to move vertically and use the y slider to move horizontally (x and y reflect indexing in the image array).<br>\nPress \"Update image\" when you want to see where you moved your cursor within the image, and press \"Remember this point\" when you want to store the current selected point into the python list `selected_image_locations`.\n\n\n`selected_image_locations` will contain all selected locations stored as couples of integers, taking the format: [(x1, y1), (x2, y2), (x3, y3) ...]\n\nThe image will show a red cross where there is the current temporary selection, and green crosses on all stored locations.\n\nIf you are not familiar with numpy arrays, we suggest to read through the code of `display_selections` and `draw_cross` as further examples."
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false
      },
      "cell_type": "code",
      "source": "selected_image_locations = list()\n\ndef draw_cross(im, cx, cy, l, w, col):\n    dimx, dimy = np.shape(im)[:2]\n    im[max(0, cx-l):min(cx+l, dimx-1), max(0, cy-w):min(dimy-1, cy+w)] = col\n    im[max(0, cx-w):min(dimx-1, cx+w), max(0, cy-l):min(dimy-1, cy+l)] = col\n\n\ndef display_selections(x, y):\n    tmp_im = np.array(bluescreen[0]*umask)\n    for px, py in selected_image_locations:\n        draw_cross(tmp_im, px, py, 1, 5, (0, 255, 0))\n    draw_cross(tmp_im, x, y, 1, 5, (255, 0, 0))\n    imshow(tmp_im)\n    \ninteractive_plot = interactive(display_selections,{'manual': True, 'manual_name': 'Update image'}, x=(0, height-1, 1), y=(0, width-1, 1))\nbutton = widgets.Button(description=\"Remember this point\")\nxslider = interactive_plot.children[0]\nyslider = interactive_plot.children[1]\nbutton.on_click(lambda b: selected_image_locations.append((xslider.value, yslider.value)))\ndisplay(button)\ndisplay(interactive_plot)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## EXERCISE 1.A - PUT SOLUTION HERE"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "selx, sely = selected_image_locations[0]\nref_rgb = bluescreen[0, selx, sely]\n\nTHRESHOLD = 200\n\ndef detect_bg(i):\n    bgmask = np.array(umask)\n    bgmask[np.linalg.norm(bluescreen[i] - ref_rgb, axis=-1) < THRESHOLD] = 0\n    return bgmask",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Note: the quality of the solution here depends on the first chosen point! You can play with selected points and threshold."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "play = widgets.Play(\n    interval=1000,\n    min=0,\n    max=numframes-1,\n    step=1,\n)\n\ndef print_frame(i):\n    imshow(bluescreen[i]*detect_bg(i))\n    \nslider = interactive(print_frame, i=(0, numframes-1, 1))\nwidgets.jslink((play, 'value'), (slider.children[0], 'value'))\nwidgets.VBox([play, slider])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "## EXERCISE 1.B - PUT SOLUTION HERE"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "exemplar_pixel_set = np.array([bluescreen[0, selx, sely] for selx, sely in selected_image_locations])  # the [`expression` for `element` in `iterator`] list constructor is just an equivalent pythonic short-hand for a for-loop\nmean = np.mean(exemplar_pixel_set, axis=0)\ninv_cov = np.linalg.inv(np.cov(exemplar_pixel_set.T))\n\nTHRESHOLD = 10\n\ndef detect_bg_mah_loop(i):\n    \"\"\"\n    Compute the background mask using the mahalanobis distance.\n    \n    This function is perfectly equivalent to detect_bg_mah_noloop, but uses explitic python looping\n    \"\"\"\n    bgmask = np.array(umask)\n    \n    for h in range(height):\n        for w in range(width):\n            residual = bluescreen[i, h, w]-mu\n            if residual.T @ inv_cov @ residual < THRESHOLD**2:\n                bgmask[h, w] = 0\n\n    return bgmask\n\ndef detect_bg_mah_noloop(i):\n    \"\"\"\n    Compute the background mask using the mahalanobis distance.\n    \n    This function is perfectly equivalent to detect_bg_mah_loop, but uses implicit numpy broadcasting rules (gains in performance)\n    \"\"\"\n    bgmask = np.array(umask)\n    \n    residuals = bluescreen[i]-mean  # precompute all differences from the mean value\n    distance_image = np.sum((residuals[:, :, np.newaxis, :] @ inv_cov)[:, :, 0, :] * residuals, axis=-1)  # build an image where each pixel is the mahalanobis distance from the corresponding source pixel. See docpage of matmul for details on its specific broadcasting rules.\n    \n    bgmask[distance_image < THRESHOLD**2] = 0  # conditional assignment of mask values based on the precomputed distance image.\n    return bgmask",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Note: the quality of the solution here depends on the chosen points! You can play with selected points and threshold."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "play = widgets.Play(\n    interval=1000,\n    min=0,\n    max=numframes-1,\n    step=1,\n)\n\ndef print_frame(i):\n    imshow(bluescreen[i]*detect_bg_mah_noloop(i))\n    \nslider = interactive(print_frame, i=(0, numframes-1, 1))\nwidgets.jslink((play, 'value'), (slider.children[0], 'value'))\nwidgets.VBox([play, slider])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "## EXERCISE 2 - SETUP CODE\n(installs and imports from the Exercise 1 should be run anyway)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Reading the test video jugglingTest.avi in `testvid` and the background reference video jugglingBG.avi into `bgvid`."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "bgvid = np.array(skvideo.io.vread(\"jugglingBG.avi\"), dtype=np.int16)\ntestvid = np.array(skvideo.io.vread(\"jugglingTest.avi\"), dtype=np.int16)\n\nbgnumframes, bgheight, bgwidth, bgchannels = np.shape(bgvid)\nprint(\"jugglingBG.avi video information:\")\nprint(\"Number of frames: \", bgnumframes)\nprint(\"Frame width (pixels): \", bgwidth)\nprint(\"Frame height (pixels): \", bgheight)\nprint(\"Video array shape: \", np.shape(bgvid))\n\nprint()\ntestnumframes, testheight, testwidth, testchannels = np.shape(testvid)\nprint(\"jugglingTest.avi video information:\")\nprint(\"Number of frames: \", testnumframes)\nprint(\"Frame width (pixels): \", testwidth)\nprint(\"Frame height (pixels): \", testheight)\nprint(\"Video array shape: \", np.shape(testvid))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## EXERCISE 2 - PUT SOLUTION HERE"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Computing the inverse covariance matrix for every pixel is going to require some time..."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "means = np.mean(bgvid, axis=0) # extract the mean value for each pixel by averaging over subsequent frames\ninv_cov_matrices = np.empty((bgheight, bgwidth, 3, 3))\n\nprogress_bar = widgets.IntProgress(min=0.0, max=bgwidth, description='')\ndisplay(progress_bar)\nfor w in range(bgwidth):\n    for h in range(bgheight):\n        inv_cov_matrices[h, w] = np.linalg.inv(np.cov(bgvid[:, h, w, :].T) + 1e-8*np.eye(3))\n    progress_bar.value += 1",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "THRESHOLD = 80\n\ndef detect_bg_perpixelmodel_loop(i):\n    \"\"\"\n    Compute the background mask using the mahalanobis distance.\n    \"\"\"\n    bgmask = np.ones(shape=(testheight, testwidth, 1), dtype=np.int16)\n    \n    for h in range(testheight):\n        for w in range(testwidth):\n            residual = testvid[i, h, w]-means[h, w]\n            if residual.T @ inv_cov_matrices[h, w] @ residual < THRESHOLD**2:\n                bgmask[h, w] = 0\n\n    return bgmask",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "play = widgets.Play(\n    interval=3000,\n    min=0,\n    max=numframes-1,\n    step=1,\n)\n\ndef print_frame(i):\n    imshow(testvid[i]*detect_bg_perpixelmodel_loop(i))\n    \nslider = interactive(print_frame, i=(0, testnumframes-1, 1))\nwidgets.jslink((play, 'value'), (slider.children[0], 'value'))\nwidgets.VBox([play, slider])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}